{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fabe637a-e6d7-42e5-aafa-88baa4d901c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src import *\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b2fa1a-1d13-464e-9da8-e9b317027e66",
   "metadata": {},
   "source": [
    "# CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aceddd65-80dc-4696-82a8-8927030b04cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is using cpu\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('PyTorch is using', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea70f808-1302-43c9-baec-466470dd8637",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9d1aa1b-8260-4910-9748-8a2ccf654b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from configs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391ed6bb-6479-44f2-a09d-f261aec341e5",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46946d01-d1ef-4a0c-bb4d-698a3ad04a2a",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c607dd2f-0e14-4482-865a-1b2b1ca8b510",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(resize_h, resize_w)),\n",
    "    transforms.ToTensor(),    \n",
    "])\n",
    "dataset = CustomDataset(dataset_name=dataset_name, transforms=transforms)\n",
    "train_loader = dataset.get_dataloader(is_train=True,\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      num_workers=num_workers,\n",
    "                                      prefetch_factor=prefetch_factor)\n",
    "test_loader = dataset.get_dataloader(is_train=False,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     num_workers=num_workers,\n",
    "                                     prefetch_factor=prefetch_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2728646-498b-4a4e-b117-10d4f371daf5",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e42ca2a0-3f88-4a8c-b1f5-e41ca0def804",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWAE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): GELU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): GELU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (7): GELU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (10): GELU()\n",
      "    (11): Dropout(p=0.1, inplace=False)\n",
      "    (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (13): GELU()\n",
      "    (14): Dropout(p=0.1, inplace=False)\n",
      "    (15): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (16): GELU()\n",
      "    (17): Dropout(p=0.1, inplace=False)\n",
      "    (18): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (z_mu): Linear(in_features=20480, out_features=1024, bias=True)\n",
      "  (z_logvar): Linear(in_features=20480, out_features=1024, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=20480, bias=True)\n",
      "    (1): Unflatten(dim=1, unflattened_size=(1024, 4, 5))\n",
      "    (2): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): GELU()\n",
      "    (4): Dropout(p=0.1, inplace=False)\n",
      "    (5): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): GELU()\n",
      "    (7): Dropout(p=0.1, inplace=False)\n",
      "    (8): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (9): GELU()\n",
      "    (10): Dropout(p=0.1, inplace=False)\n",
      "    (11): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (12): GELU()\n",
      "    (13): Dropout(p=0.1, inplace=False)\n",
      "    (14): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (15): GELU()\n",
      "    (16): Dropout(p=0.1, inplace=False)\n",
      "    (17): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (18): GELU()\n",
      "    (19): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_dim = resize_h, resize_w, input_ch\n",
    "model = IWAE(input_dim, channels, num_z, num_samples).to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = IW_ELBO(input_dim, num_samples)\n",
    "optimizer = optim.Adam(model.parameters(), lr=init_lr)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "                                        lr_lambda=lambda epoch: lr_decay ** epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d08857-f922-4e84-9ec5-b091585c1dae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Learn\n",
    "total_time = 0\n",
    "train_losses = {\"ELBO\": []}\n",
    "test_losses = {\"ELBO\": [], \"MSE\":[]}\n",
    "elapsed_times = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # generate and visualize\n",
    "    samples, recons = reconstruct(model, test_loader, device)\n",
    "    visualize_imgs(samples, recons)\n",
    "    \n",
    "    # train\n",
    "    start_time = time.time()\n",
    "    train_loss = train(epoch,\n",
    "                       model, train_loader,\n",
    "                       criterion, optimizer, scheduler,\n",
    "                       device)\n",
    "    end_time = time.time()\n",
    "    dt = end_time - start_time\n",
    "    total_time += dt\n",
    "\n",
    "    # test\n",
    "    test_elbo_loss, test_mse_loss = test(epoch,\n",
    "                                         model, test_loader,\n",
    "                                         criterion,\n",
    "                                         device)\n",
    "    \n",
    "    train_losses[\"ELBO\"].append(train_loss)\n",
    "    test_losses[\"ELBO\"].append(test_elbo_loss)\n",
    "    test_losses[\"MSE\"].append(test_mse_loss)\n",
    "    elapsed_times.append(dt)\n",
    "    \n",
    "    print(f'Epoch {epoch} / {epochs} in {dt:.2f} secs')\n",
    "    print(f'Train loss[ELBO] {train_loss:.4f}, Test loss[ELBO] {test_elbo_loss:.4f}, Test loss[MSE] {test_mse_loss:.5f}')\n",
    "\n",
    "print('Train loss[ELBO]:', train_losses[\"ELBO\"])\n",
    "print('Test loss[ELBO]:', test_losses[\"ELBO\"])\n",
    "print('Test loss[MSE]:', test_losses[\"MSE\"])\n",
    "print(f'Average {total_time / epochs:.2f} secs per epoch consumed')\n",
    "print(f'Total {total_time:.2f} secs consumed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03afe0da-cd6f-46c6-aba1-7a37f7e3874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "save_dir = \"./results\"\n",
    "save_dir = os.path.realpath(save_dir)\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# save model\n",
    "state_dict_path = os.path.join(save_dir, \"iwae_state_dict.pth\")\n",
    "state_dict = model.to('cpu').state_dict()\n",
    "torch.save(state_dict, state_dict_path)\n",
    "\n",
    "# save results\n",
    "results = {\n",
    "    \"TrainLoss-ELBO\" : train_losses[\"ELBO\"],\n",
    "    \"TestLoss-ELBO\"  : test_losses[\"ELBO\"],\n",
    "    \"TestLoss-MSE\"   : test_losses[\"MSE\"],\n",
    "    \"TrainTime\"      : elapsed_times,\n",
    "}\n",
    "results_path = os.path.join(save_dir, \"iwae_training_results.csv\")\n",
    "results_df = pd.DataFrame(results).reset_index(drop=True)\n",
    "results_df.to_csv(results_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
